{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": "# TransKal Final Training and Evaluation\n\nThis notebook trains TransKal (Transformer + Kalman Filter) with the best hyperparameters found during tuning and evaluates on the test set.\n\n**Task**: Multiclass fault classification (18 classes)\n\n**Data Split**:\n- Train: Model fitting\n- Validation: Early stopping monitoring\n- Test: Final evaluation (never seen during training)\n\n**Architecture**: Transformer classifier with adaptive Kalman filter smoothing applied per-run\n\n**Outputs**:\n- Trained model: `outputs/models/transkal_final.pt`\n- Metrics: `outputs/metrics/transkal_metrics.json`\n- Confusion matrix: `outputs/figures/transkal_confusion_matrix.png`"
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport sys\nimport time\nimport json\nimport math\nfrom pathlib import Path\n\nstart_time = time.time()\nprint(\"=\"*60)\nprint(\"TransKal Final Training and Evaluation\")\nprint(\"=\"*60)\nprint(f\"Started at: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n\n# Quick mode configuration\nQUICK_MODE = os.getenv('QUICK_MODE', 'False').lower() in ('true', '1', 'yes')\n\nif QUICK_MODE:\n    TRAIN_FRACTION = 0.01\n    MAX_EPOCHS = 1\n    PATIENCE = 1\n    print(\"ðŸš€ QUICK MODE (1% data, 1 epoch)\")\nelse:\n    TRAIN_FRACTION = 1.0\n    MAX_EPOCHS = 100\n    PATIENCE = 10\n    print(\"ðŸ”¬ FULL MODE (100% data, up to 100 epochs)\")\n\nDATA_DIR = Path('../data')\nOUTPUT_DIR = Path('../outputs')\nHYPERPARAM_DIR = OUTPUT_DIR / 'hyperparams'\nMODEL_DIR = OUTPUT_DIR / 'models'\nMETRICS_DIR = OUTPUT_DIR / 'metrics'\nFIGURES_DIR = OUTPUT_DIR / 'figures'\n\nMODEL_DIR.mkdir(parents=True, exist_ok=True)\nMETRICS_DIR.mkdir(parents=True, exist_ok=True)\nFIGURES_DIR.mkdir(parents=True, exist_ok=True)\n\nRANDOM_SEED = 42\nMODE_SUFFIX = '_quick' if QUICK_MODE else ''\n\n# Load best hyperparameters\nif (HYPERPARAM_DIR / 'transkal_best.json').exists():\n    hp_file = HYPERPARAM_DIR / 'transkal_best.json'\n    print(\"Using FULL mode hyperparameters\")\nelse:\n    hp_file = HYPERPARAM_DIR / 'transkal_best_quick.json'\n    print(\"Using QUICK mode hyperparameters\")\n\nwith open(hp_file) as f:\n    hp_data = json.load(f)\n    best_params = hp_data['best_params']\n\nprint(f\"\\nHyperparameters:\")\nfor k, v in best_params.items():\n    print(f\"  {k}: {v}\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[Step 1/6] Loading libraries...\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix, balanced_accuracy_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"âœ“ Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n[Step 2/6] Loading datasets...\")\ndata_load_start = time.time()\n\ntrain = pd.read_csv(DATA_DIR / 'multiclass_train.csv')\nval = pd.read_csv(DATA_DIR / 'multiclass_val.csv')\ntest = pd.read_csv(DATA_DIR / 'multiclass_test.csv')\n\nprint(f\"âœ“ Train: {train.shape}\")\nprint(f\"âœ“ Val: {val.shape}\")\nprint(f\"âœ“ Test: {test.shape}\")\nprint(f\"âœ“ Data loading time: {time.time() - data_load_start:.2f}s\")\n\nfeatures = [col for col in train.columns if 'xmeas' in col or 'xmv' in col]\nnum_features = len(features)\nprint(f\"âœ“ Number of features: {num_features}\")\n\n# Subsample if in quick mode (subsample runs, not random rows, to preserve sequences)\nif TRAIN_FRACTION < 1.0:\n    train_runs = train[['faultNumber', 'simulationRun']].drop_duplicates()\n    val_runs = val[['faultNumber', 'simulationRun']].drop_duplicates()\n    \n    n_train_runs = max(1, int(len(train_runs) * TRAIN_FRACTION))\n    n_val_runs = max(1, int(len(val_runs) * TRAIN_FRACTION))\n    \n    sampled_train_runs = train_runs.sample(n=n_train_runs, random_state=RANDOM_SEED)\n    sampled_val_runs = val_runs.sample(n=n_val_runs, random_state=RANDOM_SEED)\n    \n    train = train.merge(sampled_train_runs, on=['faultNumber', 'simulationRun'])\n    val = val.merge(sampled_val_runs, on=['faultNumber', 'simulationRun'])\n    \n    print(f\"âœ“ Subsampled train to {TRAIN_FRACTION*100:.1f}%: {train.shape}\")\n    print(f\"âœ“ Subsampled val to {TRAIN_FRACTION*100:.1f}%: {val.shape}\")\n\n# Fit scaler on training data only\nscaler = StandardScaler()\nscaler.fit(train[features])\n\n# Fit label encoder on training data only\nlabel_encoder = LabelEncoder()\nlabel_encoder.fit(train['faultNumber'])\nnum_classes = len(label_encoder.classes_)\nclass_names = [str(int(c)) for c in label_encoder.classes_]\nprint(f\"âœ“ Number of classes: {num_classes}\")"
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## Model and Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[Step 3/6] Defining model and dataset...\")\n",
    "\n",
    "class SimulationRunDataset(Dataset):\n",
    "    \"\"\"Dataset that creates windows WITHIN simulation runs only.\"\"\"\n",
    "    def __init__(self, df, features, scaler, label_encoder, sequence_length=10):\n",
    "        self.seq_len = sequence_length\n",
    "        self.windows = []\n",
    "        self.labels = []\n",
    "        self.run_indices = []  # Track which run each window belongs to\n",
    "        \n",
    "        run_idx = 0\n",
    "        for (fault, run), group in df.groupby(['faultNumber', 'simulationRun']):\n",
    "            group = group.sort_values('sample')\n",
    "            X = scaler.transform(group[features].values)\n",
    "            y = label_encoder.transform(group['faultNumber'].values)\n",
    "            \n",
    "            for i in range(len(X) - sequence_length + 1):\n",
    "                self.windows.append(X[i:i+sequence_length])\n",
    "                self.labels.append(y[i+sequence_length-1])\n",
    "                self.run_indices.append(run_idx)\n",
    "            run_idx += 1\n",
    "        \n",
    "        self.windows = np.array(self.windows, dtype=np.float32)\n",
    "        self.labels = np.array(self.labels, dtype=np.int64)\n",
    "        self.run_indices = np.array(self.run_indices, dtype=np.int64)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.windows[idx]), torch.tensor(self.labels[idx]), torch.tensor(self.run_indices[idx])\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    \"\"\"Transformer classifier for time series (matches v1 architecture).\"\"\"\n",
    "    def __init__(self, input_dim, num_classes, d_model=32, nhead=2, \n",
    "                 num_layers=1, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(input_dim, d_model),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, \n",
    "            dim_feedforward=d_model * 2,\n",
    "            dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) * np.sqrt(self.d_model)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "class KalmanFilter:\n",
    "    \"\"\"Adaptive Kalman filter for smoothing predictions within a single run.\"\"\"\n",
    "    def __init__(self, num_classes, Q=1e-5, R=0.1):\n",
    "        self.num_classes = num_classes\n",
    "        self.Q_base = Q\n",
    "        self.R_base = R\n",
    "        self.transition_threshold = 0.25\n",
    "        self.confidence_threshold = 0.65\n",
    "        self.stabilization_steps = 3\n",
    "        self.vote_window = 5\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.x_est = None\n",
    "        self.P = None\n",
    "        self.steps_since_transition = 100\n",
    "        self.prev_class = None\n",
    "        self.prob_history = []\n",
    "        \n",
    "    def _compute_entropy(self, probs):\n",
    "        probs = np.clip(probs, 1e-10, 1.0)\n",
    "        entropy = -np.sum(probs * np.log(probs))\n",
    "        max_entropy = np.log(len(probs))\n",
    "        return entropy / max_entropy if max_entropy > 0 else 0\n",
    "    \n",
    "    def _detect_transition(self, prev_state, curr_obs, prev_class, curr_class):\n",
    "        if curr_class == prev_class:\n",
    "            return False\n",
    "        curr_conf = np.max(curr_obs)\n",
    "        prev_class_drop = prev_state[prev_class] - curr_obs[prev_class]\n",
    "        prob_change = np.abs(curr_obs - prev_state).max()\n",
    "        if curr_conf > self.confidence_threshold and prev_class_drop > 0.15:\n",
    "            return True\n",
    "        if prob_change > self.transition_threshold and curr_conf > 0.5:\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def update(self, observation):\n",
    "        probs = np.array(observation).flatten()\n",
    "        probs = np.clip(probs, 1e-10, 1.0)\n",
    "        probs = probs / probs.sum()\n",
    "        \n",
    "        self.prob_history.append(probs.copy())\n",
    "        if len(self.prob_history) > self.vote_window:\n",
    "            self.prob_history.pop(0)\n",
    "        \n",
    "        curr_class = np.argmax(probs)\n",
    "        \n",
    "        if self.x_est is None:\n",
    "            self.x_est = probs.copy()\n",
    "            self.P = np.eye(self.num_classes) * 0.1\n",
    "            self.prev_class = curr_class\n",
    "            return self.x_est\n",
    "        \n",
    "        if self._detect_transition(self.x_est, probs, self.prev_class, curr_class):\n",
    "            self.x_est = probs.copy()\n",
    "            self.P = np.eye(self.num_classes) * 0.1\n",
    "            self.steps_since_transition = 0\n",
    "            self.prev_class = curr_class\n",
    "            return self.x_est\n",
    "        \n",
    "        entropy = self._compute_entropy(probs)\n",
    "        transition_factor = min(1.0, self.steps_since_transition / self.stabilization_steps)\n",
    "        confidence = np.max(probs)\n",
    "        \n",
    "        Q = self.Q_base * (1 + 4 * entropy) * (2 - transition_factor)\n",
    "        R = self.R_base * (1 - confidence + entropy) * transition_factor\n",
    "        \n",
    "        x_pred = self.x_est.copy()\n",
    "        P_pred = self.P + Q * np.eye(self.num_classes)\n",
    "        \n",
    "        H = np.eye(self.num_classes)\n",
    "        S = P_pred + R * np.eye(self.num_classes)\n",
    "        K = P_pred @ np.linalg.inv(S)\n",
    "        \n",
    "        self.x_est = x_pred + K @ (probs - x_pred)\n",
    "        self.x_est = np.clip(self.x_est, 0, 1)\n",
    "        self.x_est = self.x_est / self.x_est.sum()\n",
    "        \n",
    "        self.P = (np.eye(self.num_classes) - K @ H) @ P_pred\n",
    "        self.steps_since_transition += 1\n",
    "        self.prev_class = np.argmax(self.x_est)\n",
    "        \n",
    "        return self.x_est\n",
    "\n",
    "print(\"âœ“ Model and dataset classes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-datasets",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n[Step 4/6] Creating datasets...\")\ndataset_start = time.time()\n\nsequence_length = best_params['sequence_length']\nbatch_size = best_params['batch_size']\n\n# Create separate datasets for train, val, and test\ntrain_dataset = SimulationRunDataset(train, features, scaler, label_encoder, sequence_length)\nval_dataset = SimulationRunDataset(val, features, scaler, label_encoder, sequence_length)\ntest_dataset = SimulationRunDataset(test, features, scaler, label_encoder, sequence_length)\n\nprint(f\"âœ“ Train dataset: {len(train_dataset)} windows\")\nprint(f\"âœ“ Val dataset: {len(val_dataset)} windows\")\nprint(f\"âœ“ Test dataset: {len(test_dataset)} windows\")\n\n# For training and validation, we shuffle/don't shuffle appropriately\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n# For testing, we need sequential order for Kalman filter\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n\nprint(f\"âœ“ Dataset creation time: {time.time() - dataset_start:.2f}s\")"
  },
  {
   "cell_type": "markdown",
   "id": "train-header",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-model",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n[Step 5/6] Training final model with early stopping on validation set...\")\ntrain_start = time.time()\n\nmodel = TransformerClassifier(\n    input_dim=num_features,\n    num_classes=num_classes,\n    d_model=best_params['d_model'],\n    nhead=best_params['nhead'],\n    num_layers=best_params['num_layers'],\n    dropout=best_params['dropout']\n).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=best_params['learning_rate'])\n\n# Training with early stopping on validation loss\nbest_val_loss = float('inf')\npatience_counter = 0\nbest_model_state = None\nhistory = {'train_loss': [], 'val_loss': [], 'epoch': []}\n\nprint(f\"Training for up to {MAX_EPOCHS} epochs with patience {PATIENCE}...\")\n\nfor epoch in range(MAX_EPOCHS):\n    # Training phase\n    model.train()\n    train_loss = 0.0\n    \n    for X_batch, y_batch, _ in train_loader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(X_batch)\n        loss = criterion(outputs, y_batch)\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n    \n    avg_train_loss = train_loss / len(train_loader)\n    \n    # Validation phase\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for X_batch, y_batch, _ in val_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            outputs = model(X_batch)\n            loss = criterion(outputs, y_batch)\n            val_loss += loss.item()\n    \n    avg_val_loss = val_loss / len(val_loader)\n    \n    history['train_loss'].append(avg_train_loss)\n    history['val_loss'].append(avg_val_loss)\n    history['epoch'].append(epoch + 1)\n    \n    if (epoch + 1) % 5 == 0 or epoch == 0:\n        print(f\"Epoch {epoch+1}/{MAX_EPOCHS}: Train Loss = {avg_train_loss:.6f}, Val Loss = {avg_val_loss:.6f}\")\n    \n    # Early stopping on validation loss\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        patience_counter = 0\n        best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n    else:\n        patience_counter += 1\n        if patience_counter >= PATIENCE:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n\n# Restore best model\nif best_model_state is not None:\n    model.load_state_dict({k: v.to(device) for k, v in best_model_state.items()})\n\ntrain_time = time.time() - train_start\nbest_epoch = history['epoch'][history['val_loss'].index(min(history['val_loss']))]\nprint(f\"\\nâœ“ Training complete in {train_time:.2f}s ({epoch+1} epochs)\")\nprint(f\"âœ“ Best epoch: {best_epoch} (val_loss = {best_val_loss:.6f})\")"
  },
  {
   "cell_type": "markdown",
   "id": "eval-header",
   "metadata": {},
   "source": [
    "## Evaluation on Test Set (with Kalman Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n[Step 6/6] Evaluating on test set with Kalman filter...\")\n\nmodel.eval()\nkalman = KalmanFilter(num_classes, Q=best_params['kalman_Q'], R=best_params['kalman_R'])\n\n# Collect all predictions and run indices first\nall_probs = []\nall_labels = []\nall_run_indices = []\n\nwith torch.no_grad():\n    for X_batch, y_batch, run_batch in test_loader:\n        X_batch = X_batch.to(device)\n        outputs = model(X_batch)\n        probs = torch.softmax(outputs, dim=1).cpu().numpy()\n        all_probs.extend(probs)\n        all_labels.extend(y_batch.numpy())\n        all_run_indices.extend(run_batch.numpy())\n\nall_probs = np.array(all_probs)\nall_labels = np.array(all_labels)\nall_run_indices = np.array(all_run_indices)\n\n# Apply Kalman filter per run\nfiltered_preds = []\ncurrent_run = -1\n\nfor i in range(len(all_probs)):\n    if all_run_indices[i] != current_run:\n        kalman.reset()\n        current_run = all_run_indices[i]\n    \n    filtered_probs = kalman.update(all_probs[i])\n    filtered_preds.append(np.argmax(filtered_probs))\n\ny_test = all_labels\ny_pred = np.array(filtered_preds)\n\n# Also compute raw predictions for comparison\ny_pred_raw = np.argmax(all_probs, axis=1)\n\naccuracy = accuracy_score(y_test, y_pred)\nbalanced_acc = balanced_accuracy_score(y_test, y_pred)\nf1_weighted = f1_score(y_test, y_pred, average='weighted')\nf1_macro = f1_score(y_test, y_pred, average='macro')\nprecision_weighted = precision_score(y_test, y_pred, average='weighted')\nrecall_weighted = recall_score(y_test, y_pred, average='weighted')\n\n# Raw metrics for comparison\naccuracy_raw = accuracy_score(y_test, y_pred_raw)\nf1_weighted_raw = f1_score(y_test, y_pred_raw, average='weighted')\n\nprint(f\"\\n{'='*60}\")\nprint(f\"TEST SET RESULTS (with Kalman Filter) {'(QUICK MODE)' if QUICK_MODE else ''}\")\nprint(f\"{'='*60}\")\nprint(f\"Accuracy:          {accuracy:.4f} ({accuracy*100:.2f}%)\")\nprint(f\"Balanced Accuracy: {balanced_acc:.4f} ({balanced_acc*100:.2f}%)\")\nprint(f\"F1 (weighted):     {f1_weighted:.4f}\")\nprint(f\"F1 (macro):        {f1_macro:.4f}\")\nprint(f\"Precision (weighted): {precision_weighted:.4f}\")\nprint(f\"Recall (weighted):    {recall_weighted:.4f}\")\nprint(f\"{'='*60}\")\nprint(f\"\\nComparison with raw Transformer predictions:\")\nprint(f\"  Raw Accuracy: {accuracy_raw:.4f} -> With Kalman: {accuracy:.4f} ({(accuracy-accuracy_raw)*100:+.2f}%)\")\nprint(f\"  Raw F1:       {f1_weighted_raw:.4f} -> With Kalman: {f1_weighted:.4f} ({(f1_weighted-f1_weighted_raw)*100:+.2f}%)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classification-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPer-Class Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-history",
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(10, 5))\nax.plot(history['epoch'], history['train_loss'], 'b-', linewidth=2, label='Train Loss')\nax.plot(history['epoch'], history['val_loss'], 'r-', linewidth=2, label='Val Loss')\nax.axvline(x=best_epoch, color='g', linestyle='--', alpha=0.7, label=f'Best Epoch ({best_epoch})')\nax.set_xlabel('Epoch')\nax.set_ylabel('Loss')\nax.set_title(f'TransKal Training History{\" - QUICK\" if QUICK_MODE else \"\"}')\nax.legend()\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig(FIGURES_DIR / f'transkal_training_history{MODE_SUFFIX}.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confusion-matrix",
   "metadata": {},
   "outputs": [],
   "source": "cm = confusion_matrix(y_test, y_pred)\ncm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\nfig, axes = plt.subplots(1, 2, figsize=(20, 8))\n\nsns.heatmap(cm, annot=False, fmt='d', cmap='Blues', \n            xticklabels=class_names, yticklabels=class_names, ax=axes[0])\naxes[0].set_xlabel('Predicted')\naxes[0].set_ylabel('Actual')\naxes[0].set_title(f'TransKal Confusion Matrix (Counts){\" - QUICK\" if QUICK_MODE else \"\"}')\n\nsns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names, ax=axes[1])\naxes[1].set_xlabel('Predicted')\naxes[1].set_ylabel('Actual')\naxes[1].set_title(f'TransKal Confusion Matrix (Normalized){\" - QUICK\" if QUICK_MODE else \"\"}')\n\nplt.tight_layout()\nplt.savefig(FIGURES_DIR / f'transkal_confusion_matrix{MODE_SUFFIX}.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(f\"âœ“ Saved confusion matrix to {FIGURES_DIR / f'transkal_confusion_matrix{MODE_SUFFIX}.png'}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "per-class-metrics",
   "metadata": {},
   "outputs": [],
   "source": "f1_per_class = f1_score(y_test, y_pred, average=None)\n\nfig, ax = plt.subplots(figsize=(12, 6))\nbars = ax.bar(class_names, f1_per_class, color='steelblue', edgecolor='black')\nax.axhline(y=f1_weighted, color='red', linestyle='--', label=f'Weighted Avg: {f1_weighted:.4f}')\nax.set_xlabel('Fault Class')\nax.set_ylabel('F1 Score')\nax.set_title(f'TransKal Per-Class F1 Scores{\" - QUICK\" if QUICK_MODE else \"\"}')\nax.set_ylim(0, 1.05)\nax.legend()\nax.grid(axis='y', alpha=0.3)\n\nfor bar, f1 in zip(bars, f1_per_class):\n    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n            f'{f1:.3f}', ha='center', va='bottom', fontsize=8, rotation=90)\n\nplt.tight_layout()\nplt.savefig(FIGURES_DIR / f'transkal_per_class_f1{MODE_SUFFIX}.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results",
   "metadata": {},
   "outputs": [],
   "source": "end_time = time.time()\ntotal_runtime = end_time - start_time\n\nmetrics = {\n    'model': 'TransKal',\n    'task': 'multiclass',\n    'quick_mode': QUICK_MODE,\n    'train_fraction': TRAIN_FRACTION,\n    'train_samples': len(train_dataset),\n    'val_samples': len(val_dataset),\n    'test_samples': len(test_dataset),\n    'best_epoch': best_epoch,\n    'best_val_loss': float(best_val_loss),\n    'accuracy': float(accuracy),\n    'balanced_accuracy': float(balanced_acc),\n    'f1_weighted': float(f1_weighted),\n    'f1_macro': float(f1_macro),\n    'precision_weighted': float(precision_weighted),\n    'recall_weighted': float(recall_weighted),\n    'raw_accuracy': float(accuracy_raw),\n    'raw_f1_weighted': float(f1_weighted_raw),\n    'kalman_improvement_accuracy': float(accuracy - accuracy_raw),\n    'kalman_improvement_f1': float(f1_weighted - f1_weighted_raw),\n    'per_class_f1': {class_names[i]: float(f1_per_class[i]) for i in range(num_classes)},\n    'hyperparameters': best_params,\n    'epochs_trained': len(history['epoch']),\n    'training_time_seconds': float(train_time),\n    'total_runtime_seconds': float(total_runtime),\n    'random_seed': RANDOM_SEED\n}\n\nwith open(METRICS_DIR / f'transkal_metrics{MODE_SUFFIX}.json', 'w') as f:\n    json.dump(metrics, f, indent=2)\nprint(f\"âœ“ Saved metrics to {METRICS_DIR / f'transkal_metrics{MODE_SUFFIX}.json'}\")\n\ntorch.save({\n    'model_state_dict': model.state_dict(),\n    'model_config': {\n        'input_dim': num_features,\n        'num_classes': num_classes,\n        'd_model': best_params['d_model'],\n        'nhead': best_params['nhead'],\n        'num_layers': best_params['num_layers'],\n        'dropout': best_params['dropout'],\n        'sequence_length': sequence_length\n    },\n    'kalman_params': {\n        'Q': best_params['kalman_Q'],\n        'R': best_params['kalman_R']\n    },\n    'scaler_mean': scaler.mean_.tolist(),\n    'scaler_scale': scaler.scale_.tolist(),\n    'label_encoder_classes': label_encoder.classes_.tolist(),\n    'features': features\n}, MODEL_DIR / f'transkal_final{MODE_SUFFIX}.pt')\nprint(f\"âœ“ Saved model to {MODEL_DIR / f'transkal_final{MODE_SUFFIX}.pt'}\")\n\ncm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\ncm_df.to_csv(METRICS_DIR / f'transkal_confusion_matrix{MODE_SUFFIX}.csv')\nprint(f\"âœ“ Saved confusion matrix to {METRICS_DIR / f'transkal_confusion_matrix{MODE_SUFFIX}.csv'}\")\n\nprint(f\"\\n{'='*60}\")\nprint(f\"âœ“ TransKal Final Training Complete! {'(QUICK MODE)' if QUICK_MODE else ''}\")\nprint(f\"{'='*60}\")\nprint(f\"Total runtime: {int(total_runtime // 60)}m {int(total_runtime % 60)}s\")\nprint(f\"Best epoch: {best_epoch}\")\nprint(f\"Test Accuracy: {accuracy:.4f}\")\nprint(f\"Test F1 (weighted): {f1_weighted:.4f}\")\nprint(f\"{'='*60}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}