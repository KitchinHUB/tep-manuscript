{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Generate New TEP Evaluation Dataset\n",
    "\n",
    "This notebook generates a completely new, independent TEP dataset using `tep-sim` for evaluating trained models on unseen data.\n",
    "\n",
    "**Purpose**: Create an independent evaluation dataset to test model generalization beyond the original test set.\n",
    "\n",
    "**Dataset Specifications**:\n",
    "- **Duration**: 48 hours per simulation (same as original test set)\n",
    "- **Sampling interval**: 3 minutes (180 seconds) → 960 samples per simulation\n",
    "- **Fault introduction**: At hour 8 (sample 161), same as original test set\n",
    "- **Fault classes**: 18 total (0=normal, 1, 2, 4-8, 10-14, 16-20; excluding 3, 9, 15)\n",
    "\n",
    "**Output Files**:\n",
    "- `data/new_multiclass_eval.csv` - Multiclass evaluation (~2.16M samples from 150 runs/class)\n",
    "- `data/new_binary_eval.csv` - Binary anomaly detection evaluation (~1.3M samples)\n",
    "\n",
    "**Generation Time**: ~12 hours (full mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T01:24:23.160320Z",
     "iopub.status.busy": "2026-01-08T01:24:23.160018Z",
     "iopub.status.idle": "2026-01-08T01:24:23.475558Z",
     "shell.execute_reply": "2026-01-08T01:24:23.474687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "QUICK MODE ENABLED - Full duration, minimal runs\n",
      "============================================================\n",
      "Duration: 48.0 hours per simulation\n",
      "Sampling: 180 seconds (3 minutes)\n",
      "Samples per run: 961 total, 801 post-fault\n",
      "Fault onset: Hour 8.0 (sample 161)\n",
      "Fault classes: 18 ([0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20])\n",
      "Runs per class (multiclass): 3\n",
      "Normal runs (binary): 3\n",
      "Fault runs per class (binary): 2\n",
      "Total multiclass runs: 54\n",
      "Total binary runs: 37\n",
      "Expected multiclass samples: ~43,254\n",
      "Expected binary samples: ~30,117\n",
      "Estimated generation time: ~0.7 hours\n",
      "Output files will have '_quick' suffix\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tep import TEPSimulator\n",
    "\n",
    "# =============================================================================\n",
    "# QUICK MODE: Set to True for fast testing with minimal data\n",
    "# Can be set via environment variable or directly here\n",
    "# =============================================================================\n",
    "QUICK_MODE = os.environ.get('QUICK_MODE', 'False').lower() in ('true', '1', 'yes')\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path('../data')\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Simulation parameters\n",
    "FAULT_ONSET_HOURS = 8.0         # Fault introduced at hour 8\n",
    "FAULT_ONSET_SAMPLE = 161        # Sample 161 (0-indexed: 160) = 8 hours at 3-min sampling\n",
    "\n",
    "# Fault classes (matching original dataset, excluding 3, 9, 15)\n",
    "FAULT_CLASSES = [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20]\n",
    "NUM_CLASSES = len(FAULT_CLASSES)\n",
    "\n",
    "# Random seed offset (different from original which used 42)\n",
    "SEED_OFFSET = 1000\n",
    "\n",
    "if QUICK_MODE:\n",
    "    # Quick mode: full 48h duration (comparable trajectories) but minimal runs\n",
    "    DURATION_HOURS = 48.0           # 48 hours - same as full mode for comparable trajectories\n",
    "    RECORD_INTERVAL = 180           # 3 minutes\n",
    "    RUNS_PER_CLASS = 3              # 3 runs per class (54 total runs)\n",
    "    NORMAL_RUNS_BINARY = 3          # 3 normal runs\n",
    "    FAULT_RUNS_BINARY = 2           # 2 runs per fault\n",
    "    FILE_SUFFIX = '_quick'\n",
    "    print(\"=\"*60)\n",
    "    print(\"QUICK MODE ENABLED - Full duration, minimal runs\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    # Full mode: Large dataset for robust evaluation (~12 hours to generate)\n",
    "    # 48h simulation = 960 samples, post-fault = 800 samples per run\n",
    "    # Target: statistically robust evaluation with <2% impact from single-run failures\n",
    "    DURATION_HOURS = 48.0           # 48 hours per simulation\n",
    "    RECORD_INTERVAL = 180           # 3 minutes = 180 seconds\n",
    "    RUNS_PER_CLASS = 150            # 150 runs per fault class for multiclass\n",
    "    NORMAL_RUNS_BINARY = 300        # 300 normal runs for binary\n",
    "    FAULT_RUNS_BINARY = 75          # 75 runs per fault for binary\n",
    "    FILE_SUFFIX = ''\n",
    "    print(\"=\"*60)\n",
    "    print(\"TEP New Dataset Generation (FULL MODE - LARGE)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Calculate expected samples\n",
    "samples_per_run = int((DURATION_HOURS * 3600 / RECORD_INTERVAL)) + 1\n",
    "post_fault_samples = samples_per_run - FAULT_ONSET_SAMPLE + 1\n",
    "expected_multiclass = RUNS_PER_CLASS * NUM_CLASSES * post_fault_samples\n",
    "expected_binary_normal = NORMAL_RUNS_BINARY * samples_per_run\n",
    "expected_binary_fault = FAULT_RUNS_BINARY * (NUM_CLASSES - 1) * post_fault_samples\n",
    "expected_binary = expected_binary_normal + expected_binary_fault\n",
    "\n",
    "# Estimate generation time (~26 sec per simulation)\n",
    "total_multiclass_runs = RUNS_PER_CLASS * NUM_CLASSES\n",
    "total_binary_runs = NORMAL_RUNS_BINARY + FAULT_RUNS_BINARY * (NUM_CLASSES - 1)\n",
    "est_time_hours = (total_multiclass_runs + total_binary_runs) * 26 / 3600\n",
    "\n",
    "print(f\"Duration: {DURATION_HOURS} hours per simulation\")\n",
    "print(f\"Sampling: {RECORD_INTERVAL} seconds ({RECORD_INTERVAL/60:.0f} minutes)\")\n",
    "print(f\"Samples per run: {samples_per_run} total, {post_fault_samples} post-fault\")\n",
    "print(f\"Fault onset: Hour {FAULT_ONSET_HOURS} (sample {FAULT_ONSET_SAMPLE})\")\n",
    "print(f\"Fault classes: {NUM_CLASSES} ({FAULT_CLASSES})\")\n",
    "print(f\"Runs per class (multiclass): {RUNS_PER_CLASS}\")\n",
    "print(f\"Normal runs (binary): {NORMAL_RUNS_BINARY}\")\n",
    "print(f\"Fault runs per class (binary): {FAULT_RUNS_BINARY}\")\n",
    "print(f\"Total multiclass runs: {total_multiclass_runs}\")\n",
    "print(f\"Total binary runs: {total_binary_runs}\")\n",
    "print(f\"Expected multiclass samples: ~{expected_multiclass:,}\")\n",
    "print(f\"Expected binary samples: ~{expected_binary:,}\")\n",
    "print(f\"Estimated generation time: ~{est_time_hours:.1f} hours\")\n",
    "if QUICK_MODE:\n",
    "    print(f\"Output files will have '{FILE_SUFFIX}' suffix\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gen-header",
   "metadata": {},
   "source": [
    "## Dataset Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gen-functions",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T01:24:23.479456Z",
     "iopub.status.busy": "2026-01-08T01:24:23.479167Z",
     "iopub.status.idle": "2026-01-08T01:24:23.487163Z",
     "shell.execute_reply": "2026-01-08T01:24:23.486025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Functions defined\n"
     ]
    }
   ],
   "source": [
    "def run_simulation(fault_number, seed, duration_hours=DURATION_HOURS, \n",
    "                   fault_onset_hours=FAULT_ONSET_HOURS, record_interval=RECORD_INTERVAL):\n",
    "    \"\"\"\n",
    "    Run a single TEP simulation with optional fault injection.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fault_number : int\n",
    "        Fault ID (0 = normal, 1-20 = faults)\n",
    "    seed : int\n",
    "        Random seed for reproducibility\n",
    "    duration_hours : float\n",
    "        Total simulation duration in hours\n",
    "    fault_onset_hours : float\n",
    "        Time at which to introduce fault (hours)\n",
    "    record_interval : int\n",
    "        Recording interval in seconds\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with keys: 'measurements', 'manipulated', 'time', 'shutdown'\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    sim = TEPSimulator(random_seed=seed)\n",
    "    sim.initialize()\n",
    "    \n",
    "    # Set up disturbances\n",
    "    if fault_number == 0:\n",
    "        disturbances = None\n",
    "    else:\n",
    "        # Introduce fault at specified time\n",
    "        disturbances = {fault_number: (fault_onset_hours, 1)}\n",
    "    \n",
    "    result = sim.simulate(\n",
    "        duration_hours=duration_hours,\n",
    "        disturbances=disturbances,\n",
    "        record_interval=record_interval\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'measurements': result.measurements,           # Shape: (samples, 41)\n",
    "        'manipulated': result.manipulated_vars[:, :11], # Shape: (samples, 11) - use first 11\n",
    "        'time': result.time,\n",
    "        'shutdown': result.shutdown\n",
    "    }\n",
    "\n",
    "\n",
    "def simulation_to_dataframe(sim_result, fault_number, run_number, origin='new'):\n",
    "    \"\"\"\n",
    "    Convert simulation result to DataFrame matching original data format.\n",
    "    \n",
    "    Columns: faultNumber, simulationRun, sample, xmeas_1...xmeas_41, xmv_1...xmv_11, origin, traj_key\n",
    "    \"\"\"\n",
    "    n_samples = len(sim_result['time'])\n",
    "    \n",
    "    # Build data dictionary\n",
    "    data = {\n",
    "        'faultNumber': [fault_number] * n_samples,\n",
    "        'simulationRun': [float(run_number)] * n_samples,\n",
    "        'sample': list(range(1, n_samples + 1))  # 1-indexed like original\n",
    "    }\n",
    "    \n",
    "    # Add XMEAS columns (41 measurements)\n",
    "    for i in range(41):\n",
    "        data[f'xmeas_{i+1}'] = sim_result['measurements'][:, i]\n",
    "    \n",
    "    # Add XMV columns (11 manipulated variables)\n",
    "    for i in range(11):\n",
    "        data[f'xmv_{i+1}'] = sim_result['manipulated'][:, i]\n",
    "    \n",
    "    # Add metadata\n",
    "    data['origin'] = [origin] * n_samples\n",
    "    data['traj_key'] = [f'{origin}_f{fault_number}_r{run_number}'] * n_samples\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(\"✓ Functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-header",
   "metadata": {},
   "source": [
    "## Test Single Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "test-sim",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T01:24:23.489742Z",
     "iopub.status.busy": "2026-01-08T01:24:23.489597Z",
     "iopub.status.idle": "2026-01-08T01:24:34.394163Z",
     "shell.execute_reply": "2026-01-08T01:24:34.391784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing single simulation...\n",
      "Normal simulation: 961 samples, shutdown=False\n",
      "Fault 1 simulation: 961 samples, shutdown=False\n",
      "\n",
      "DataFrame shape: (961, 57)\n",
      "Columns: ['faultNumber', 'simulationRun', 'sample', 'xmeas_1', 'xmeas_2', 'xmeas_3', 'xmeas_4', 'xmeas_5']...['xmv_11', 'origin', 'traj_key']\n",
      "\n",
      "✓ Test complete in 51.55s\n",
      "Estimated time for full dataset: 46.4 minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing single simulation...\")\n",
    "test_start = time.time()\n",
    "\n",
    "# Test normal operation\n",
    "result_normal = run_simulation(fault_number=0, seed=SEED_OFFSET)\n",
    "print(f\"Normal simulation: {result_normal['measurements'].shape[0]} samples, \"\n",
    "      f\"shutdown={result_normal['shutdown']}\")\n",
    "\n",
    "# Test fault 1\n",
    "result_fault = run_simulation(fault_number=1, seed=SEED_OFFSET + 1)\n",
    "print(f\"Fault 1 simulation: {result_fault['measurements'].shape[0]} samples, \"\n",
    "      f\"shutdown={result_fault['shutdown']}\")\n",
    "\n",
    "# Convert to DataFrame and verify format\n",
    "df_test = simulation_to_dataframe(result_fault, fault_number=1, run_number=1)\n",
    "print(f\"\\nDataFrame shape: {df_test.shape}\")\n",
    "print(f\"Columns: {list(df_test.columns)[:8]}...{list(df_test.columns)[-3:]}\")\n",
    "\n",
    "test_time = time.time() - test_start\n",
    "print(f\"\\n✓ Test complete in {test_time:.2f}s\")\n",
    "print(f\"Estimated time for full dataset: {test_time * RUNS_PER_CLASS * NUM_CLASSES / 60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiclass-header",
   "metadata": {},
   "source": [
    "## Generate Multiclass Evaluation Dataset\n",
    "\n",
    "Generate desired runs per fault class (18 classes). Use only post-fault samples (161-960) for balanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gen-multiclass",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T01:24:34.398785Z",
     "iopub.status.busy": "2026-01-08T01:24:34.398559Z",
     "iopub.status.idle": "2026-01-08T01:27:47.904413Z",
     "shell.execute_reply": "2026-01-08T01:27:47.902834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Generating Multiclass Evaluation Dataset\n",
      "============================================================\n",
      "\n",
      "Fault 0 (1/18)...\n",
      "  Completed in 77.5s\n",
      "\n",
      "Fault 1 (2/18)...\n",
      "  Completed in 77.7s\n",
      "\n",
      "Fault 2 (3/18)...\n",
      "  Completed in 77.6s\n",
      "\n",
      "Fault 4 (4/18)...\n",
      "  Completed in 77.8s\n",
      "\n",
      "Fault 5 (5/18)...\n",
      "  Completed in 77.7s\n",
      "\n",
      "Fault 6 (6/18)...\n",
      "  Completed in 22.5s\n",
      "\n",
      "Fault 7 (7/18)...\n",
      "  Completed in 77.6s\n",
      "\n",
      "Fault 8 (8/18)...\n",
      "  Completed in 77.6s\n",
      "\n",
      "Fault 10 (9/18)...\n",
      "  Completed in 77.2s\n",
      "\n",
      "Fault 11 (10/18)...\n",
      "  Completed in 77.1s\n",
      "\n",
      "Fault 12 (11/18)...\n",
      "  Completed in 61.4s\n",
      "\n",
      "Fault 13 (12/18)...\n",
      "  Completed in 77.5s\n",
      "\n",
      "Fault 14 (13/18)...\n",
      "  Completed in 77.4s\n",
      "\n",
      "Fault 16 (14/18)...\n",
      "  Completed in 77.4s\n",
      "\n",
      "Fault 17 (15/18)...\n",
      "  Completed in 77.2s\n",
      "\n",
      "Fault 18 (16/18)...\n",
      "  Completed in 38.4s\n",
      "\n",
      "Fault 19 (17/18)...\n",
      "  Completed in 77.4s\n",
      "\n",
      "Fault 20 (18/18)...\n",
      "  Completed in 77.4s\n",
      "\n",
      "Combining DataFrames...\n",
      "\n",
      "✓ Multiclass dataset generated in 21.4 minutes\n",
      "  Shape: (39157, 57)\n",
      "  Samples per class: [2403 2403 2403 2403 2403  356 2403 2403 2403 2403 1800 2403 2403 2403\n",
      " 2403  956 2403 2403]\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Generating Multiclass Evaluation Dataset\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "all_dfs = []\n",
    "total_runs = RUNS_PER_CLASS * NUM_CLASSES\n",
    "completed = 0\n",
    "\n",
    "for fault_idx, fault_number in enumerate(FAULT_CLASSES):\n",
    "    fault_start = time.time()\n",
    "    print(f\"\\nFault {fault_number} ({fault_idx+1}/{NUM_CLASSES})...\")\n",
    "    \n",
    "    for run in range(1, RUNS_PER_CLASS + 1):\n",
    "        # Unique seed for each simulation\n",
    "        seed = SEED_OFFSET + fault_number * 1000 + run\n",
    "        \n",
    "        try:\n",
    "            result = run_simulation(fault_number=fault_number, seed=seed)\n",
    "            df = simulation_to_dataframe(result, fault_number, run, origin='new_eval')\n",
    "            \n",
    "            # For multiclass: use only post-fault samples (161 onwards)\n",
    "            # This gives 800 samples per run (961 - 161 = 800)\n",
    "            df_post_fault = df[df['sample'] >= FAULT_ONSET_SAMPLE].copy()\n",
    "            all_dfs.append(df_post_fault)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Fault {fault_number} run {run} failed: {e}\")\n",
    "        \n",
    "        completed += 1\n",
    "        if run % 50 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            eta = elapsed / completed * (total_runs - completed)\n",
    "            print(f\"  Run {run}/{RUNS_PER_CLASS} - \"\n",
    "                  f\"Progress: {completed}/{total_runs} ({100*completed/total_runs:.1f}%) - \"\n",
    "                  f\"ETA: {eta/60:.1f} min\")\n",
    "    \n",
    "    fault_time = time.time() - fault_start\n",
    "    print(f\"  Completed in {fault_time:.1f}s\")\n",
    "\n",
    "# Combine all DataFrames\n",
    "print(\"\\nCombining DataFrames...\")\n",
    "multiclass_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n✓ Multiclass dataset generated in {total_time/60:.1f} minutes\")\n",
    "print(f\"  Shape: {multiclass_df.shape}\")\n",
    "print(f\"  Samples per class: {multiclass_df.groupby('faultNumber').size().values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "save-multiclass",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T01:27:47.907903Z",
     "iopub.status.busy": "2026-01-08T01:27:47.907707Z",
     "iopub.status.idle": "2026-01-08T01:27:48.120326Z",
     "shell.execute_reply": "2026-01-08T01:27:48.119076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving multiclass dataset to ../data/new_multiclass_eval_quick.csv...\n",
      "✓ Saved (38.9 MB)\n",
      "\n",
      "Class distribution:\n",
      "faultNumber\n",
      "0     2403\n",
      "1     2403\n",
      "2     2403\n",
      "4     2403\n",
      "5     2403\n",
      "6      356\n",
      "7     2403\n",
      "8     2403\n",
      "10    2403\n",
      "11    2403\n",
      "12    1800\n",
      "13    2403\n",
      "14    2403\n",
      "16    2403\n",
      "17    2403\n",
      "18     956\n",
      "19    2403\n",
      "20    2403\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Save multiclass dataset\n",
    "output_file = DATA_DIR / f'new_multiclass_eval{FILE_SUFFIX}.csv'\n",
    "print(f\"Saving multiclass dataset to {output_file}...\")\n",
    "multiclass_df.to_csv(output_file, index=False)\n",
    "file_size = output_file.stat().st_size\n",
    "if file_size > 1e9:\n",
    "    print(f\"✓ Saved ({file_size / 1e9:.2f} GB)\")\n",
    "else:\n",
    "    print(f\"✓ Saved ({file_size / 1e6:.1f} MB)\")\n",
    "\n",
    "# Verify class balance\n",
    "print(\"\\nClass distribution:\")\n",
    "print(multiclass_df['faultNumber'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-header",
   "metadata": {},
   "source": [
    "## Generate Binary Evaluation Dataset\n",
    "\n",
    "Generate:\n",
    "- 300 normal runs (all samples)\n",
    "- 75 runs per fault (17 faults, post-fault samples only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "gen-binary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T01:27:48.123782Z",
     "iopub.status.busy": "2026-01-08T01:27:48.123620Z",
     "iopub.status.idle": "2026-01-08T01:29:30.787396Z",
     "shell.execute_reply": "2026-01-08T01:29:30.785838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Generating Binary Evaluation Dataset\n",
      "============================================================\n",
      "\n",
      "Generating normal runs (120 runs, all samples)...\n",
      "  ✓ Normal runs complete\n",
      "\n",
      "Generating fault runs (17 faults × 2 runs)...\n",
      "  Progress: 5/17 faults\n",
      "  Progress: 10/17 faults\n",
      "  Progress: 15/17 faults\n",
      "\n",
      "Combining DataFrames...\n",
      "\n",
      "✓ Binary dataset generated in 15.0 minutes\n",
      "  Shape: (27846, 57)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Generating Binary Evaluation Dataset\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "binary_dfs = []\n",
    "\n",
    "# Generate normal runs (all samples)\n",
    "print(\"\\nGenerating normal runs (120 runs, all samples)...\")\n",
    "for run in range(1, NORMAL_RUNS_BINARY + 1):\n",
    "    seed = SEED_OFFSET + 50000 + run  # Different seed range from multiclass\n",
    "    \n",
    "    try:\n",
    "        result = run_simulation(fault_number=0, seed=seed)\n",
    "        df = simulation_to_dataframe(result, fault_number=0, run_number=run, origin='new_binary')\n",
    "        binary_dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Normal run {run} failed: {e}\")\n",
    "    \n",
    "    if run % 30 == 0:\n",
    "        print(f\"  Progress: {run}/{NORMAL_RUNS_BINARY}\")\n",
    "\n",
    "print(f\"  ✓ Normal runs complete\")\n",
    "\n",
    "# Generate fault runs (post-fault samples only)\n",
    "fault_classes_no_normal = [f for f in FAULT_CLASSES if f != 0]\n",
    "print(f\"\\nGenerating fault runs ({len(fault_classes_no_normal)} faults × {FAULT_RUNS_BINARY} runs)...\")\n",
    "\n",
    "for fault_idx, fault_number in enumerate(fault_classes_no_normal):\n",
    "    for run in range(1, FAULT_RUNS_BINARY + 1):\n",
    "        seed = SEED_OFFSET + 60000 + fault_number * 100 + run\n",
    "        \n",
    "        try:\n",
    "            result = run_simulation(fault_number=fault_number, seed=seed)\n",
    "            df = simulation_to_dataframe(result, fault_number=fault_number, run_number=run, origin='new_binary')\n",
    "            # Use only post-fault samples\n",
    "            df_post_fault = df[df['sample'] >= FAULT_ONSET_SAMPLE].copy()\n",
    "            binary_dfs.append(df_post_fault)\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Fault {fault_number} run {run} failed: {e}\")\n",
    "    \n",
    "    if (fault_idx + 1) % 5 == 0:\n",
    "        print(f\"  Progress: {fault_idx+1}/{len(fault_classes_no_normal)} faults\")\n",
    "\n",
    "# Combine\n",
    "print(\"\\nCombining DataFrames...\")\n",
    "binary_df = pd.concat(binary_dfs, ignore_index=True)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n✓ Binary dataset generated in {total_time/60:.1f} minutes\")\n",
    "print(f\"  Shape: {binary_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "save-binary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T01:29:30.791135Z",
     "iopub.status.busy": "2026-01-08T01:29:30.790958Z",
     "iopub.status.idle": "2026-01-08T01:29:30.953713Z",
     "shell.execute_reply": "2026-01-08T01:29:30.952666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving binary dataset to ../data/new_binary_eval_quick.csv...\n",
      "✓ Saved (27.9 MB)\n",
      "\n",
      "Binary distribution:\n",
      "  Normal: 2,883 (10.4%)\n",
      "  Fault:  24,963 (89.6%)\n"
     ]
    }
   ],
   "source": [
    "# Add binary label column\n",
    "binary_df['label'] = (binary_df['faultNumber'] != 0).astype(int)\n",
    "\n",
    "# Save binary dataset\n",
    "output_file = DATA_DIR / f'new_binary_eval{FILE_SUFFIX}.csv'\n",
    "print(f\"Saving binary dataset to {output_file}...\")\n",
    "binary_df.to_csv(output_file, index=False)\n",
    "print(f\"✓ Saved ({output_file.stat().st_size / 1e6:.1f} MB)\")\n",
    "\n",
    "# Statistics\n",
    "n_normal = (binary_df['label'] == 0).sum()\n",
    "n_fault = (binary_df['label'] == 1).sum()\n",
    "print(f\"\\nBinary distribution:\")\n",
    "print(f\"  Normal: {n_normal:,} ({100*n_normal/len(binary_df):.1f}%)\")\n",
    "print(f\"  Fault:  {n_fault:,} ({100*n_fault/len(binary_df):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify-header",
   "metadata": {},
   "source": [
    "## Verify Dataset Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "verify",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T01:29:30.956767Z",
     "iopub.status.busy": "2026-01-08T01:29:30.956603Z",
     "iopub.status.idle": "2026-01-08T01:29:30.989154Z",
     "shell.execute_reply": "2026-01-08T01:29:30.987904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Dataset Verification\n",
      "============================================================\n",
      "\n",
      "Multiclass Dataset:\n",
      "  Shape: (39157, 57)\n",
      "  Classes: [np.int64(0), np.int64(1), np.int64(2), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(16), np.int64(17), np.int64(18), np.int64(19), np.int64(20)]\n",
      "  Samples per class: 356 - 2403\n",
      "  Missing values: 0\n",
      "\n",
      "Binary Dataset:\n",
      "  Shape: (27846, 58)\n",
      "  Normal samples: 2,883\n",
      "  Fault samples: 24,963\n",
      "  Missing values: 0\n",
      "\n",
      "============================================================\n",
      "✓ Quick Dataset Generation Complete!\n",
      "  Files saved with '_quick' suffix\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Dataset Verification\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load and verify multiclass\n",
    "print(\"\\nMulticlass Dataset:\")\n",
    "mc = pd.read_csv(DATA_DIR / f'new_multiclass_eval{FILE_SUFFIX}.csv')\n",
    "print(f\"  Shape: {mc.shape}\")\n",
    "print(f\"  Classes: {sorted(mc['faultNumber'].unique())}\")\n",
    "print(f\"  Samples per class: {mc.groupby('faultNumber').size().min()} - {mc.groupby('faultNumber').size().max()}\")\n",
    "print(f\"  Missing values: {mc.isnull().sum().sum()}\")\n",
    "\n",
    "# Load and verify binary\n",
    "print(\"\\nBinary Dataset:\")\n",
    "bn = pd.read_csv(DATA_DIR / f'new_binary_eval{FILE_SUFFIX}.csv')\n",
    "print(f\"  Shape: {bn.shape}\")\n",
    "print(f\"  Normal samples: {(bn['label'] == 0).sum():,}\")\n",
    "print(f\"  Fault samples: {(bn['label'] == 1).sum():,}\")\n",
    "print(f\"  Missing values: {bn.isnull().sum().sum()}\")\n",
    "\n",
    "# Compare with original test sets (only in full mode)\n",
    "if not QUICK_MODE:\n",
    "    print(\"\\nComparison with Original Test Sets:\")\n",
    "    orig_mc = pd.read_csv(DATA_DIR / 'multiclass_test.csv')\n",
    "    orig_bn = pd.read_csv(DATA_DIR / 'binary_test.csv')\n",
    "    print(f\"  Original multiclass: {orig_mc.shape}\")\n",
    "    print(f\"  New multiclass:      {mc.shape}\")\n",
    "    print(f\"  Original binary:     {orig_bn.shape}\")\n",
    "    print(f\"  New binary:          {bn.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if QUICK_MODE:\n",
    "    print(\"✓ Quick Dataset Generation Complete!\")\n",
    "    print(f\"  Files saved with '{FILE_SUFFIX}' suffix\")\n",
    "else:\n",
    "    print(\"✓ Dataset Generation Complete!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
