{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Generate New TEP Evaluation Dataset\n",
    "\n",
    "This notebook generates a completely new, independent TEP dataset using `tep-sim` for evaluating trained models on unseen data.\n",
    "\n",
    "**Purpose**: Create an independent evaluation dataset to test model generalization beyond the original test set.\n",
    "\n",
    "**Dataset Specifications**:\n",
    "- **Duration**: 48 hours per simulation (same as original test set)\n",
    "- **Sampling interval**: 3 minutes (180 seconds) → 960 samples per simulation\n",
    "- **Fault introduction**: At hour 8 (sample 161), same as original test set\n",
    "- **Fault classes**: 18 total (0=normal, 1, 2, 4-8, 10-14, 16-20; excluding 3, 9, 15)\n",
    "\n",
    "**Output Files**:\n",
    "- `data/new_multiclass_eval.csv` - Multiclass evaluation (~2.16M samples from 150 runs/class)\n",
    "- `data/new_binary_eval.csv` - Binary anomaly detection evaluation (~1.3M samples)\n",
    "\n",
    "**Generation Time**: ~12 hours (full mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "config",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T03:01:07.008435Z",
     "iopub.status.busy": "2026-01-08T03:01:07.008115Z",
     "iopub.status.idle": "2026-01-08T03:01:08.230216Z",
     "shell.execute_reply": "2026-01-08T03:01:08.228313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEP New Dataset Generation (FULL MODE - LARGE)\n",
      "============================================================\n",
      "Duration: 48.0 hours per simulation\n",
      "Sampling: 180 seconds (3 minutes)\n",
      "Samples per run: 961 total, 801 post-fault\n",
      "Fault onset: Hour 8.0 (sample 161)\n",
      "Fault classes: 18 ([0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20])\n",
      "Runs per class (multiclass): 150\n",
      "Normal runs (binary): 300\n",
      "Fault runs per class (binary): 75\n",
      "Total multiclass runs: 2700\n",
      "Total binary runs: 1575\n",
      "Expected multiclass samples: ~2,162,700\n",
      "Expected binary samples: ~1,309,575\n",
      "Estimated generation time: ~30.9 hours\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tep import TEPSimulator\n",
    "\n",
    "# =============================================================================\n",
    "# QUICK MODE: Set to True for fast testing with minimal data\n",
    "# Can be set via environment variable or directly here\n",
    "# =============================================================================\n",
    "QUICK_MODE = os.environ.get('QUICK_MODE', 'False').lower() in ('true', '1', 'yes')\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path('../data')\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Simulation parameters\n",
    "FAULT_ONSET_HOURS = 8.0         # Fault introduced at hour 8\n",
    "FAULT_ONSET_SAMPLE = 161        # Sample 161 (0-indexed: 160) = 8 hours at 3-min sampling\n",
    "\n",
    "# Fault classes (matching original dataset, excluding 3, 9, 15)\n",
    "FAULT_CLASSES = [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20]\n",
    "NUM_CLASSES = len(FAULT_CLASSES)\n",
    "\n",
    "# Random seed offset (different from original which used 42)\n",
    "SEED_OFFSET = 1000\n",
    "\n",
    "if QUICK_MODE:\n",
    "    # Quick mode: full 48h duration (comparable trajectories) but minimal runs\n",
    "    DURATION_HOURS = 48.0           # 48 hours - same as full mode for comparable trajectories\n",
    "    RECORD_INTERVAL = 180           # 3 minutes\n",
    "    RUNS_PER_CLASS = 3              # 3 runs per class (54 total runs)\n",
    "    NORMAL_RUNS_BINARY = 3          # 3 normal runs\n",
    "    FAULT_RUNS_BINARY = 2           # 2 runs per fault\n",
    "    FILE_SUFFIX = '_quick'\n",
    "    print(\"=\"*60)\n",
    "    print(\"QUICK MODE ENABLED - Full duration, minimal runs\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    # Full mode: Large dataset for robust evaluation (~12 hours to generate)\n",
    "    # 48h simulation = 960 samples, post-fault = 800 samples per run\n",
    "    # Target: statistically robust evaluation with <2% impact from single-run failures\n",
    "    DURATION_HOURS = 48.0           # 48 hours per simulation\n",
    "    RECORD_INTERVAL = 180           # 3 minutes = 180 seconds\n",
    "    RUNS_PER_CLASS = 150            # 150 runs per fault class for multiclass\n",
    "    NORMAL_RUNS_BINARY = 300        # 300 normal runs for binary\n",
    "    FAULT_RUNS_BINARY = 75          # 75 runs per fault for binary\n",
    "    FILE_SUFFIX = ''\n",
    "    print(\"=\"*60)\n",
    "    print(\"TEP New Dataset Generation (FULL MODE - LARGE)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Calculate expected samples\n",
    "samples_per_run = int((DURATION_HOURS * 3600 / RECORD_INTERVAL)) + 1\n",
    "post_fault_samples = samples_per_run - FAULT_ONSET_SAMPLE + 1\n",
    "expected_multiclass = RUNS_PER_CLASS * NUM_CLASSES * post_fault_samples\n",
    "expected_binary_normal = NORMAL_RUNS_BINARY * samples_per_run\n",
    "expected_binary_fault = FAULT_RUNS_BINARY * (NUM_CLASSES - 1) * post_fault_samples\n",
    "expected_binary = expected_binary_normal + expected_binary_fault\n",
    "\n",
    "# Estimate generation time (~26 sec per simulation)\n",
    "total_multiclass_runs = RUNS_PER_CLASS * NUM_CLASSES\n",
    "total_binary_runs = NORMAL_RUNS_BINARY + FAULT_RUNS_BINARY * (NUM_CLASSES - 1)\n",
    "est_time_hours = (total_multiclass_runs + total_binary_runs) * 26 / 3600\n",
    "\n",
    "print(f\"Duration: {DURATION_HOURS} hours per simulation\")\n",
    "print(f\"Sampling: {RECORD_INTERVAL} seconds ({RECORD_INTERVAL/60:.0f} minutes)\")\n",
    "print(f\"Samples per run: {samples_per_run} total, {post_fault_samples} post-fault\")\n",
    "print(f\"Fault onset: Hour {FAULT_ONSET_HOURS} (sample {FAULT_ONSET_SAMPLE})\")\n",
    "print(f\"Fault classes: {NUM_CLASSES} ({FAULT_CLASSES})\")\n",
    "print(f\"Runs per class (multiclass): {RUNS_PER_CLASS}\")\n",
    "print(f\"Normal runs (binary): {NORMAL_RUNS_BINARY}\")\n",
    "print(f\"Fault runs per class (binary): {FAULT_RUNS_BINARY}\")\n",
    "print(f\"Total multiclass runs: {total_multiclass_runs}\")\n",
    "print(f\"Total binary runs: {total_binary_runs}\")\n",
    "print(f\"Expected multiclass samples: ~{expected_multiclass:,}\")\n",
    "print(f\"Expected binary samples: ~{expected_binary:,}\")\n",
    "print(f\"Estimated generation time: ~{est_time_hours:.1f} hours\")\n",
    "if QUICK_MODE:\n",
    "    print(f\"Output files will have '{FILE_SUFFIX}' suffix\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gen-header",
   "metadata": {},
   "source": [
    "## Dataset Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gen-functions",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T03:01:08.235076Z",
     "iopub.status.busy": "2026-01-08T03:01:08.234541Z",
     "iopub.status.idle": "2026-01-08T03:01:08.248549Z",
     "shell.execute_reply": "2026-01-08T03:01:08.247039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Functions defined\n"
     ]
    }
   ],
   "source": [
    "def run_simulation(fault_number, seed, duration_hours=DURATION_HOURS, \n",
    "                   fault_onset_hours=FAULT_ONSET_HOURS, record_interval=RECORD_INTERVAL):\n",
    "    \"\"\"\n",
    "    Run a single TEP simulation with optional fault injection.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fault_number : int\n",
    "        Fault ID (0 = normal, 1-20 = faults)\n",
    "    seed : int\n",
    "        Random seed for reproducibility\n",
    "    duration_hours : float\n",
    "        Total simulation duration in hours\n",
    "    fault_onset_hours : float\n",
    "        Time at which to introduce fault (hours)\n",
    "    record_interval : int\n",
    "        Recording interval in seconds\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with keys: 'measurements', 'manipulated', 'time', 'shutdown'\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    sim = TEPSimulator(random_seed=seed)\n",
    "    sim.initialize()\n",
    "    \n",
    "    # Set up disturbances\n",
    "    if fault_number == 0:\n",
    "        disturbances = None\n",
    "    else:\n",
    "        # Introduce fault at specified time\n",
    "        disturbances = {fault_number: (fault_onset_hours, 1)}\n",
    "    \n",
    "    result = sim.simulate(\n",
    "        duration_hours=duration_hours,\n",
    "        disturbances=disturbances,\n",
    "        record_interval=record_interval\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'measurements': result.measurements,           # Shape: (samples, 41)\n",
    "        'manipulated': result.manipulated_vars[:, :11], # Shape: (samples, 11) - use first 11\n",
    "        'time': result.time,\n",
    "        'shutdown': result.shutdown\n",
    "    }\n",
    "\n",
    "\n",
    "def simulation_to_dataframe(sim_result, fault_number, run_number, origin='new'):\n",
    "    \"\"\"\n",
    "    Convert simulation result to DataFrame matching original data format.\n",
    "    \n",
    "    Columns: faultNumber, simulationRun, sample, xmeas_1...xmeas_41, xmv_1...xmv_11, origin, traj_key\n",
    "    \"\"\"\n",
    "    n_samples = len(sim_result['time'])\n",
    "    \n",
    "    # Build data dictionary\n",
    "    data = {\n",
    "        'faultNumber': [fault_number] * n_samples,\n",
    "        'simulationRun': [float(run_number)] * n_samples,\n",
    "        'sample': list(range(1, n_samples + 1))  # 1-indexed like original\n",
    "    }\n",
    "    \n",
    "    # Add XMEAS columns (41 measurements)\n",
    "    for i in range(41):\n",
    "        data[f'xmeas_{i+1}'] = sim_result['measurements'][:, i]\n",
    "    \n",
    "    # Add XMV columns (11 manipulated variables)\n",
    "    for i in range(11):\n",
    "        data[f'xmv_{i+1}'] = sim_result['manipulated'][:, i]\n",
    "    \n",
    "    # Add metadata\n",
    "    data['origin'] = [origin] * n_samples\n",
    "    data['traj_key'] = [f'{origin}_f{fault_number}_r{run_number}'] * n_samples\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(\"✓ Functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-header",
   "metadata": {},
   "source": [
    "## Test Single Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "test-sim",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T03:01:08.252028Z",
     "iopub.status.busy": "2026-01-08T03:01:08.251707Z",
     "iopub.status.idle": "2026-01-08T03:02:00.094345Z",
     "shell.execute_reply": "2026-01-08T03:02:00.093069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing single simulation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal simulation: 961 samples, shutdown=False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fault 1 simulation: 961 samples, shutdown=False\n",
      "\n",
      "DataFrame shape: (961, 57)\n",
      "Columns: ['faultNumber', 'simulationRun', 'sample', 'xmeas_1', 'xmeas_2', 'xmeas_3', 'xmeas_4', 'xmeas_5']...['xmv_11', 'origin', 'traj_key']\n",
      "\n",
      "✓ Test complete in 51.83s\n",
      "Estimated time for full dataset: 2332.5 minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing single simulation...\")\n",
    "test_start = time.time()\n",
    "\n",
    "# Test normal operation\n",
    "result_normal = run_simulation(fault_number=0, seed=SEED_OFFSET)\n",
    "print(f\"Normal simulation: {result_normal['measurements'].shape[0]} samples, \"\n",
    "      f\"shutdown={result_normal['shutdown']}\")\n",
    "\n",
    "# Test fault 1\n",
    "result_fault = run_simulation(fault_number=1, seed=SEED_OFFSET + 1)\n",
    "print(f\"Fault 1 simulation: {result_fault['measurements'].shape[0]} samples, \"\n",
    "      f\"shutdown={result_fault['shutdown']}\")\n",
    "\n",
    "# Convert to DataFrame and verify format\n",
    "df_test = simulation_to_dataframe(result_fault, fault_number=1, run_number=1)\n",
    "print(f\"\\nDataFrame shape: {df_test.shape}\")\n",
    "print(f\"Columns: {list(df_test.columns)[:8]}...{list(df_test.columns)[-3:]}\")\n",
    "\n",
    "test_time = time.time() - test_start\n",
    "print(f\"\\n✓ Test complete in {test_time:.2f}s\")\n",
    "print(f\"Estimated time for full dataset: {test_time * RUNS_PER_CLASS * NUM_CLASSES / 60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiclass-header",
   "metadata": {},
   "source": [
    "## Generate Multiclass Evaluation Dataset\n",
    "\n",
    "Generate desired runs per fault class (18 classes). Use only post-fault samples (161-960) for balanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gen-multiclass",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T03:02:00.100123Z",
     "iopub.status.busy": "2026-01-08T03:02:00.099936Z",
     "iopub.status.idle": "2026-01-08T21:07:08.973561Z",
     "shell.execute_reply": "2026-01-08T21:07:08.972355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Generating Multiclass Evaluation Dataset\n",
      "============================================================\n",
      "\n",
      "Fault 0 (1/18)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 50/150 - Progress: 50/2700 (1.9%) - ETA: 1143.6 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 100/150 - Progress: 100/2700 (3.7%) - ETA: 1122.3 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 150/150 - Progress: 150/2700 (5.6%) - ETA: 1100.5 min\n",
      "  Completed in 3884.0s\n",
      "\n",
      "Fault 1 (2/18)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 50/150 - Progress: 200/2700 (7.4%) - ETA: 1079.8 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 100/150 - Progress: 250/2700 (9.3%) - ETA: 1058.4 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 150/150 - Progress: 300/2700 (11.1%) - ETA: 1037.1 min\n",
      "  Completed in 3894.2s\n",
      "\n",
      "Fault 2 (3/18)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 50/150 - Progress: 350/2700 (13.0%) - ETA: 1015.7 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 100/150 - Progress: 400/2700 (14.8%) - ETA: 994.3 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 150/150 - Progress: 450/2700 (16.7%) - ETA: 972.6 min\n",
      "  Completed in 3892.6s\n",
      "\n",
      "Fault 4 (4/18)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 50/150 - Progress: 500/2700 (18.5%) - ETA: 951.1 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 100/150 - Progress: 550/2700 (20.4%) - ETA: 929.4 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 150/150 - Progress: 600/2700 (22.2%) - ETA: 908.0 min\n",
      "  Completed in 3894.7s\n",
      "\n",
      "Fault 5 (5/18)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 50/150 - Progress: 650/2700 (24.1%) - ETA: 886.4 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 100/150 - Progress: 700/2700 (25.9%) - ETA: 864.8 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 150/150 - Progress: 750/2700 (27.8%) - ETA: 843.1 min\n",
      "  Completed in 3891.7s\n",
      "\n",
      "Fault 6 (6/18)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 50/150 - Progress: 800/2700 (29.6%) - ETA: 785.1 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 100/150 - Progress: 850/2700 (31.5%) - ETA: 733.1 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 150/150 - Progress: 900/2700 (33.3%) - ETA: 686.2 min\n",
      "  Completed in 1129.8s\n",
      "\n",
      "Fault 7 (7/18)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 50/150 - Progress: 950/2700 (35.2%) - ETA: 671.8 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 100/150 - Progress: 1000/2700 (37.0%) - ETA: 656.7 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 150/150 - Progress: 1050/2700 (38.9%) - ETA: 641.0 min\n",
      "  Completed in 3887.2s\n",
      "\n",
      "Fault 8 (8/18)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 50/150 - Progress: 1100/2700 (40.7%) - ETA: 624.7 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 100/150 - Progress: 1150/2700 (42.6%) - ETA: 608.1 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 150/150 - Progress: 1200/2700 (44.4%) - ETA: 591.0 min\n",
      "  Completed in 3895.6s\n",
      "\n",
      "Fault 10 (9/18)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 50/150 - Progress: 1250/2700 (46.3%) - ETA: 573.6 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 100/150 - Progress: 1300/2700 (48.1%) - ETA: 555.7 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 150/150 - Progress: 1350/2700 (50.0%) - ETA: 537.7 min\n",
      "  Completed in 3892.2s\n",
      "\n",
      "Fault 11 (10/18)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 50/150 - Progress: 1400/2700 (51.9%) - ETA: 519.4 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 100/150 - Progress: 1450/2700 (53.7%) - ETA: 500.8 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 150/150 - Progress: 1500/2700 (55.6%) - ETA: 482.1 min\n",
      "  Completed in 3891.8s\n",
      "\n",
      "Fault 12 (11/18)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 50/150 - Progress: 1550/2700 (57.4%) - ETA: 461.7 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 100/150 - Progress: 1600/2700 (59.3%) - ETA: 441.8 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 150/150 - Progress: 1650/2700 (61.1%) - ETA: 421.8 min\n",
      "  Completed in 3614.6s\n",
      "\n",
      "Fault 13 (12/18)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 50/150 - Progress: 1700/2700 (63.0%) - ETA: 402.4 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 100/150 - Progress: 1750/2700 (64.8%) - ETA: 382.8 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 150/150 - Progress: 1800/2700 (66.7%) - ETA: 363.4 min\n",
      "  Completed in 3839.6s\n",
      "\n",
      "Fault 14 (13/18)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 50/150 - Progress: 1850/2700 (68.5%) - ETA: 343.9 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 100/150 - Progress: 1900/2700 (70.4%) - ETA: 324.2 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 150/150 - Progress: 1950/2700 (72.2%) - ETA: 304.5 min\n",
      "  Completed in 3891.5s\n",
      "\n",
      "Fault 16 (14/18)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 50/150 - Progress: 2000/2700 (74.1%) - ETA: 284.7 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 100/150 - Progress: 2050/2700 (75.9%) - ETA: 264.8 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 150/150 - Progress: 2100/2700 (77.8%) - ETA: 244.8 min\n",
      "  Completed in 3906.8s\n",
      "\n",
      "Fault 17 (15/18)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 50/150 - Progress: 2150/2700 (79.6%) - ETA: 224.7 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 100/150 - Progress: 2200/2700 (81.5%) - ETA: 204.6 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 150/150 - Progress: 2250/2700 (83.3%) - ETA: 184.4 min\n",
      "  Completed in 3907.1s\n",
      "\n",
      "Fault 18 (16/18)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 50/150 - Progress: 2300/2700 (85.2%) - ETA: 162.3 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 100/150 - Progress: 2350/2700 (87.0%) - ETA: 140.7 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 150/150 - Progress: 2400/2700 (88.9%) - ETA: 119.4 min\n",
      "  Completed in 2006.7s\n",
      "\n",
      "Fault 19 (17/18)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 50/150 - Progress: 2450/2700 (90.7%) - ETA: 99.7 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 100/150 - Progress: 2500/2700 (92.6%) - ETA: 79.9 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 150/150 - Progress: 2550/2700 (94.4%) - ETA: 60.0 min\n",
      "  Completed in 3893.9s\n",
      "\n",
      "Fault 20 (18/18)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 50/150 - Progress: 2600/2700 (96.3%) - ETA: 40.1 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 100/150 - Progress: 2650/2700 (98.1%) - ETA: 20.1 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 150/150 - Progress: 2700/2700 (100.0%) - ETA: 0.0 min\n",
      "  Completed in 3894.2s\n",
      "\n",
      "Combining DataFrames...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Multiclass dataset generated in 1085.1 minutes\n",
      "  Shape: (1978215, 57)\n",
      "  Samples per class: [120150 120150 120150 120150 120150  17883 120150 120150 120150 120150\n",
      " 109829 118055 120150 120150 120150  50348 120150 120150]\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Generating Multiclass Evaluation Dataset\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "all_dfs = []\n",
    "total_runs = RUNS_PER_CLASS * NUM_CLASSES\n",
    "completed = 0\n",
    "\n",
    "for fault_idx, fault_number in enumerate(FAULT_CLASSES):\n",
    "    fault_start = time.time()\n",
    "    print(f\"\\nFault {fault_number} ({fault_idx+1}/{NUM_CLASSES})...\")\n",
    "    \n",
    "    for run in range(1, RUNS_PER_CLASS + 1):\n",
    "        # Unique seed for each simulation\n",
    "        seed = SEED_OFFSET + fault_number * 1000 + run\n",
    "        \n",
    "        try:\n",
    "            result = run_simulation(fault_number=fault_number, seed=seed)\n",
    "            df = simulation_to_dataframe(result, fault_number, run, origin='new_eval')\n",
    "            \n",
    "            # For multiclass: use only post-fault samples (161 onwards)\n",
    "            # This gives 800 samples per run (961 - 161 = 800)\n",
    "            df_post_fault = df[df['sample'] >= FAULT_ONSET_SAMPLE].copy()\n",
    "            all_dfs.append(df_post_fault)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Fault {fault_number} run {run} failed: {e}\")\n",
    "        \n",
    "        completed += 1\n",
    "        if run % 50 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            eta = elapsed / completed * (total_runs - completed)\n",
    "            print(f\"  Run {run}/{RUNS_PER_CLASS} - \"\n",
    "                  f\"Progress: {completed}/{total_runs} ({100*completed/total_runs:.1f}%) - \"\n",
    "                  f\"ETA: {eta/60:.1f} min\")\n",
    "    \n",
    "    fault_time = time.time() - fault_start\n",
    "    print(f\"  Completed in {fault_time:.1f}s\")\n",
    "\n",
    "# Combine all DataFrames\n",
    "print(\"\\nCombining DataFrames...\")\n",
    "multiclass_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n✓ Multiclass dataset generated in {total_time/60:.1f} minutes\")\n",
    "print(f\"  Shape: {multiclass_df.shape}\")\n",
    "print(f\"  Samples per class: {multiclass_df.groupby('faultNumber').size().values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "save-multiclass",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T21:07:08.977905Z",
     "iopub.status.busy": "2026-01-08T21:07:08.977730Z",
     "iopub.status.idle": "2026-01-08T21:11:30.001591Z",
     "shell.execute_reply": "2026-01-08T21:11:29.999923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving multiclass dataset to ../data/new_multiclass_eval.csv...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved (1.97 GB)\n",
      "\n",
      "Class distribution:\n",
      "faultNumber\n",
      "0     120150\n",
      "1     120150\n",
      "2     120150\n",
      "4     120150\n",
      "5     120150\n",
      "6      17883\n",
      "7     120150\n",
      "8     120150\n",
      "10    120150\n",
      "11    120150\n",
      "12    109829\n",
      "13    118055\n",
      "14    120150\n",
      "16    120150\n",
      "17    120150\n",
      "18     50348\n",
      "19    120150\n",
      "20    120150\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Save multiclass dataset\n",
    "output_file = DATA_DIR / f'new_multiclass_eval{FILE_SUFFIX}.csv'\n",
    "print(f\"Saving multiclass dataset to {output_file}...\")\n",
    "multiclass_df.to_csv(output_file, index=False)\n",
    "file_size = output_file.stat().st_size\n",
    "if file_size > 1e9:\n",
    "    print(f\"✓ Saved ({file_size / 1e9:.2f} GB)\")\n",
    "else:\n",
    "    print(f\"✓ Saved ({file_size / 1e6:.1f} MB)\")\n",
    "\n",
    "# Verify class balance\n",
    "print(\"\\nClass distribution:\")\n",
    "print(multiclass_df['faultNumber'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-header",
   "metadata": {},
   "source": [
    "## Generate Binary Evaluation Dataset\n",
    "\n",
    "Generate:\n",
    "- 300 normal runs (all samples)\n",
    "- 75 runs per fault (17 faults, post-fault samples only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "gen-binary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T21:11:30.005469Z",
     "iopub.status.busy": "2026-01-08T21:11:30.005292Z",
     "iopub.status.idle": "2026-01-09T07:51:05.991716Z",
     "shell.execute_reply": "2026-01-09T07:51:05.990324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Generating Binary Evaluation Dataset\n",
      "============================================================\n",
      "\n",
      "Generating normal runs (120 runs, all samples)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 30/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 90/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 120/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 150/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 180/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 210/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 240/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 270/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 300/300\n",
      "  ✓ Normal runs complete\n",
      "\n",
      "Generating fault runs (17 faults × 75 runs)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 5/17 faults\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 10/17 faults\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 15/17 faults\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combining DataFrames...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Binary dataset generated in 639.6 minutes\n",
      "  Shape: (1215860, 57)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Generating Binary Evaluation Dataset\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "binary_dfs = []\n",
    "\n",
    "# Generate normal runs (all samples)\n",
    "print(\"\\nGenerating normal runs (120 runs, all samples)...\")\n",
    "for run in range(1, NORMAL_RUNS_BINARY + 1):\n",
    "    seed = SEED_OFFSET + 50000 + run  # Different seed range from multiclass\n",
    "    \n",
    "    try:\n",
    "        result = run_simulation(fault_number=0, seed=seed)\n",
    "        df = simulation_to_dataframe(result, fault_number=0, run_number=run, origin='new_binary')\n",
    "        binary_dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Normal run {run} failed: {e}\")\n",
    "    \n",
    "    if run % 30 == 0:\n",
    "        print(f\"  Progress: {run}/{NORMAL_RUNS_BINARY}\")\n",
    "\n",
    "print(f\"  ✓ Normal runs complete\")\n",
    "\n",
    "# Generate fault runs (post-fault samples only)\n",
    "fault_classes_no_normal = [f for f in FAULT_CLASSES if f != 0]\n",
    "print(f\"\\nGenerating fault runs ({len(fault_classes_no_normal)} faults × {FAULT_RUNS_BINARY} runs)...\")\n",
    "\n",
    "for fault_idx, fault_number in enumerate(fault_classes_no_normal):\n",
    "    for run in range(1, FAULT_RUNS_BINARY + 1):\n",
    "        seed = SEED_OFFSET + 60000 + fault_number * 100 + run\n",
    "        \n",
    "        try:\n",
    "            result = run_simulation(fault_number=fault_number, seed=seed)\n",
    "            df = simulation_to_dataframe(result, fault_number=fault_number, run_number=run, origin='new_binary')\n",
    "            # Use only post-fault samples\n",
    "            df_post_fault = df[df['sample'] >= FAULT_ONSET_SAMPLE].copy()\n",
    "            binary_dfs.append(df_post_fault)\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Fault {fault_number} run {run} failed: {e}\")\n",
    "    \n",
    "    if (fault_idx + 1) % 5 == 0:\n",
    "        print(f\"  Progress: {fault_idx+1}/{len(fault_classes_no_normal)} faults\")\n",
    "\n",
    "# Combine\n",
    "print(\"\\nCombining DataFrames...\")\n",
    "binary_df = pd.concat(binary_dfs, ignore_index=True)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n✓ Binary dataset generated in {total_time/60:.1f} minutes\")\n",
    "print(f\"  Shape: {binary_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "save-binary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T07:51:05.995478Z",
     "iopub.status.busy": "2026-01-09T07:51:05.995323Z",
     "iopub.status.idle": "2026-01-09T07:53:47.123358Z",
     "shell.execute_reply": "2026-01-09T07:53:47.121791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving binary dataset to ../data/new_binary_eval.csv...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved (1219.1 MB)\n",
      "\n",
      "Binary distribution:\n",
      "  Normal: 288,300 (23.7%)\n",
      "  Fault:  927,560 (76.3%)\n"
     ]
    }
   ],
   "source": [
    "# Add binary label column\n",
    "binary_df['label'] = (binary_df['faultNumber'] != 0).astype(int)\n",
    "\n",
    "# Save binary dataset\n",
    "output_file = DATA_DIR / f'new_binary_eval{FILE_SUFFIX}.csv'\n",
    "print(f\"Saving binary dataset to {output_file}...\")\n",
    "binary_df.to_csv(output_file, index=False)\n",
    "print(f\"✓ Saved ({output_file.stat().st_size / 1e6:.1f} MB)\")\n",
    "\n",
    "# Statistics\n",
    "n_normal = (binary_df['label'] == 0).sum()\n",
    "n_fault = (binary_df['label'] == 1).sum()\n",
    "print(f\"\\nBinary distribution:\")\n",
    "print(f\"  Normal: {n_normal:,} ({100*n_normal/len(binary_df):.1f}%)\")\n",
    "print(f\"  Fault:  {n_fault:,} ({100*n_fault/len(binary_df):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify-header",
   "metadata": {},
   "source": [
    "## Verify Dataset Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "verify",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T07:53:47.127186Z",
     "iopub.status.busy": "2026-01-09T07:53:47.127005Z",
     "iopub.status.idle": "2026-01-09T07:54:26.828554Z",
     "shell.execute_reply": "2026-01-09T07:54:26.827058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Dataset Verification\n",
      "============================================================\n",
      "\n",
      "Multiclass Dataset:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Shape: (1978215, 57)\n",
      "  Classes: [np.int64(0), np.int64(1), np.int64(2), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(16), np.int64(17), np.int64(18), np.int64(19), np.int64(20)]\n",
      "  Samples per class: 17883 - 120150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Missing values: 0\n",
      "\n",
      "Binary Dataset:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Shape: (1215860, 58)\n",
      "  Normal samples: 288,300\n",
      "  Fault samples: 927,560\n",
      "  Missing values: 0\n",
      "\n",
      "Comparison with Original Test Sets:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Original multiclass: (2880000, 57)\n",
      "  New multiclass:      (1978215, 57)\n",
      "  Original binary:     (795200, 57)\n",
      "  New binary:          (1215860, 58)\n",
      "\n",
      "============================================================\n",
      "✓ Dataset Generation Complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Dataset Verification\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load and verify multiclass\n",
    "print(\"\\nMulticlass Dataset:\")\n",
    "mc = pd.read_csv(DATA_DIR / f'new_multiclass_eval{FILE_SUFFIX}.csv')\n",
    "print(f\"  Shape: {mc.shape}\")\n",
    "print(f\"  Classes: {sorted(mc['faultNumber'].unique())}\")\n",
    "print(f\"  Samples per class: {mc.groupby('faultNumber').size().min()} - {mc.groupby('faultNumber').size().max()}\")\n",
    "print(f\"  Missing values: {mc.isnull().sum().sum()}\")\n",
    "\n",
    "# Load and verify binary\n",
    "print(\"\\nBinary Dataset:\")\n",
    "bn = pd.read_csv(DATA_DIR / f'new_binary_eval{FILE_SUFFIX}.csv')\n",
    "print(f\"  Shape: {bn.shape}\")\n",
    "print(f\"  Normal samples: {(bn['label'] == 0).sum():,}\")\n",
    "print(f\"  Fault samples: {(bn['label'] == 1).sum():,}\")\n",
    "print(f\"  Missing values: {bn.isnull().sum().sum()}\")\n",
    "\n",
    "# Compare with original test sets (only in full mode)\n",
    "if not QUICK_MODE:\n",
    "    print(\"\\nComparison with Original Test Sets:\")\n",
    "    orig_mc = pd.read_csv(DATA_DIR / 'multiclass_test.csv')\n",
    "    orig_bn = pd.read_csv(DATA_DIR / 'binary_test.csv')\n",
    "    print(f\"  Original multiclass: {orig_mc.shape}\")\n",
    "    print(f\"  New multiclass:      {mc.shape}\")\n",
    "    print(f\"  Original binary:     {orig_bn.shape}\")\n",
    "    print(f\"  New binary:          {bn.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if QUICK_MODE:\n",
    "    print(\"✓ Quick Dataset Generation Complete!\")\n",
    "    print(f\"  Files saved with '{FILE_SUFFIX}' suffix\")\n",
    "else:\n",
    "    print(\"✓ Dataset Generation Complete!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
